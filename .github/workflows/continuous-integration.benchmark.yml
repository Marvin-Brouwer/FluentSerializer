name: "Continuous integration - Benchmark"
on:
  workflow_call:
    inputs:
      libraryName:
        type: string
        required: true
      reportPrefix:
        type: string
        required: true
      jobTypePrimary:
        type: string
        required: true
      jobTypeSecondary:
        type: string
        required: false
        default: "Medium"

env:
  DOTNET_VERBOSITY: "${{ (secrets.ACTIONS_STEP_DEBUG == true) && 'detailed' || 'minimal' }}"

defaults:
  run:
    # Set the shell to wsl default, empty bash caused issues so using this:
    # https://github.com/Vampire/setup-wsl#wsl-shell-command
    shell: bash --noprofile --norc -euo pipefail {0}

jobs:
  benchmark:
    name: "${{ matrix.version.displayName }} - ${{ matrix.os.displayName }}"
    strategy:
      fail-fast: true
      matrix:
        # Benchmark for all applicable frameworks, only report the latest and only run the latest on primary setting
        version: [
          {displayName: "net 7.0", sdkVersion: "7.0.x", framework: "net7.0", report: "net_7_0", jobType: "${{ inputs.jobTypePrimary }}", reportSummary: true },
          {displayName: "net 6.0", sdkVersion: "6.0.x", framework: "net6.0", report: "net_6_0", jobType: "${{ inputs.jobTypeSecondary }}" },
          {displayName: "netcoreapp 3.1", sdkVersion: "3.1.x", framework: "netcoreapp3.1", report: "netcoreapp_3_1", jobType: "${{ inputs.jobTypeSecondary }}" }
        ]
        # Benchmark for windows and linux, since this library probably is more applicable to server hosted solutions.
        os: [
          { name: windows-latest, displayName: windows, rid: "win-x64" },
          { name: ubuntu-latest, displayName: linux, rid: "linux-x64" }
        ]
        # Add a windows-only netframework benchmark, since that's only available on windows.
        include:
          # netframework only supports windows
          - version: {displayName: "netframework 4.8", sdkVersion: "3.1.x", framework: "net48", report: "netframework_4_8", jobType: "${{ inputs.jobTypeSecondary }}" }
            os: { name: windows-latest, displayName: windows, rid: "win-x64" }
    runs-on: ${{ matrix.os.name }}
    ###
    # 🗃 Setup WSL
    #
    # Enable WSL when running on windows, this will help making the scripts more uniform
    ###
    steps:
    - name: 🗃 Setup WSL
      if: runner.os == 'Windows'
      uses: Vampire/setup-wsl@v2
    ###
    # Checkout repository
    ###
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        lfs: true
    ###
    # 🧰 Install .Net SDKs
    #
    # Configure the pipeline to use the correct .Net sdk versions
    ###
    - name: 🧰 Install .Net SDKs
      uses: actions/setup-dotnet@v3
      with:
        dotnet-version: ${{ matrix.version.sdkVersion }}
    ###
    # ⏱ Benchmark FluentSerializer.${{ matrix.library.name }}
    #
    # Benchmark the code in the given library
    # `shell: pwsh` because that'll ensure the native process is used when `dotnet run` is called.
    ###
    - name: ⏱ Benchmark FluentSerializer.${{ inputs.libraryName }}
      shell: pwsh
      run: >-
        dotnet run
        --configuration "Release"
        --framework ${{ matrix.version.framework }}
        --runtime ${{ matrix.os.rid }}
        --no-self-contained
        --verbosity ${{ env.DOTNET_VERBOSITY }}
        --
        --os-displayName=${{ matrix.os.displayName }}
        --jobType=${{ matrix.version.jobType }}
        --quick-exit

        Write-Host "::remove-matcher owner=csc::"

        Write-Host "::remove-matcher owner=dotnet::"

      working-directory: ${{github.workspace}}/src/FluentSerializer.${{ inputs.libraryName }}.Benchmark/
    ###
    # 🗃 Collect benchmark reports
    ###
    - name: 🗃 Collect benchmark reports
      if: ${{ !cancelled() && success() }}
      run: |-
        dir=$(pwd);
        mkdir $dir/benchmark-results
        cd $dir/src/FluentSerializer.${{ inputs.libraryName }}.Benchmark/BenchmarkDotNet.Artifacts/results
        mv ./${{ inputs.reportPrefix }}-*.md $dir/benchmark-results/
      working-directory: ${{github.workspace}}
    ###
    # 📈 Report benchmarks
    #
    # Publish benchmark results to job overview
    ###
    - name: 📈 Report benchmarks
      if: ${{ !cancelled() && success() && matrix.version.reportSummary }}
      run: |-
        cat ./${{ inputs.reportPrefix }}-benchmark-${{ matrix.version.report }}-github.md >>$GITHUB_STEP_SUMMARY
      working-directory: ${{github.workspace}}/src/FluentSerializer.${{ inputs.libraryName }}.Benchmark/BenchmarkDotNet.Artifacts/
    ###
    # 🗃 Publish 'benchmark-results' artifacts
    ###
    - name: 🗃 Publish 'benchmark-results' artifacts
      if: ${{ !cancelled() && success() }}
      uses: actions/upload-artifact@v3
      with:
        name: benchmark-results
        path: ${{github.workspace}}/benchmark-results
        retention-days: 20